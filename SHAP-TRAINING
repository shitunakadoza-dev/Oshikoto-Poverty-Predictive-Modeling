import numpy as np
import pandas as pd
import time
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.feature_selection import SelectKBest, chi2
import shap

np.random.seed(42)
num_samples = 1000
num_full_features = 350  # Simulating full feature set

# Generate random dataset
X = np.random.rand(num_samples, num_full_features)
y = np.random.randint(0, 2, num_samples)  # Binary target variable

# Feature Selection using Chi-Square Test
k_best = 50  # Selecting top 50 features
chi2_selector = SelectKBest(chi2, k=k_best)
X_selected = chi2_selector.fit_transform(X, y)

# Splitting dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

# Standardizing features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Models dictionary
models = {
    "Logistic Regression": LogisticRegression(),
    "Extreme Gradient Boosting (ExGBM)": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    "LightGBM": LGBMClassifier()
}

# Step 2 & 3: Train models & evaluate performance
train_results = []
test_results = []

for model_name, model in models.items():
    # Training the model
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # SHAP Feature Importance Calculation
    explainer = shap.Explainer(model, X_train)
    shap_values = explainer(X_train)
    shap.summary_plot(shap_values, X_train)

    # Predictions on test set
    y_pred_test = model.predict(X_test)
    y_prob_test = model.predict_proba(X_test)[:, 1]

    # Performance metrics on test set
    accuracy_test = accuracy_score(y_test, y_pred_test)
    precision_test = precision_score(y_test, y_pred_test)
    recall_test = recall_score(y_test, y_pred_test)
    f1_test = f1_score(y_test, y_pred_test)
    auc_roc_test = roc_auc_score(y_test, y_prob_test)

    # Store results for testing
    test_results.append([model_name, accuracy_test, precision_test, recall_test, f1_test, auc_roc_test, training_time])

# Convert results into a DataFrame
results_test_df = pd.DataFrame(test_results, columns=["Model", "Accuracy", "Precision", "Recall", "F1-score", "AUC-ROC", "TT (sec)"])

# Step 4: Highlight Best Performance Values in the Table
def highlight_best(s):
    is_max = s == s.max()
    return ['background-color: lightgreen' if v else '' for v in is_max]

styled_table_test = results_test_df.style.apply(highlight_best, subset=["Accuracy", "Precision", "Recall", "F1-score", "AUC-ROC", "TT (sec)"])
display(styled_table_test)

# Step 5: Save Test Results as CSV File
csv_test_file_path = "/content/Model_performance_results_test.csv"
results_test_df.to_csv(csv_test_file_path, index=False)
files.download(csv_test_file_path)  # Auto-download CSV

# Step 6: Plot Test Results as Bar Chart
plt.figure(figsize=(12, 6))
ax = sns.barplot(data=results_test_df.melt(id_vars=["Model"], var_name="Metric", value_name="Value"),
                 x="Metric", y="Value", hue="Model", palette="Set2")

# Formatting
plt.title("Model Performance Comparison (Testing Full Feature Set)", fontsize=14, fontweight='bold')
plt.ylabel("Score", fontsize=12)
plt.xticks(rotation=45)
plt.legend(title="Models")

# Save the plot as an image and auto-download it
plot_test_path = "/content/Model_performance_comparison_test.png"
plt.savefig(plot_test_path, bbox_inches="tight")
files.download(plot_test_path)  # Auto-download plot

plt.show()
